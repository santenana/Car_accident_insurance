{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cars(url,main_div,estructura_1,estructura_2,imagen):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # clase_sup = soup.find_all(\"lo\", {\"class\":'ui-search-layout ui-search-layout--grid'})\n",
    "    divs = soup.find_all(main_div[0], {\"class\":main_div[1]})\n",
    "    # print(divs)\n",
    "    carros = []\n",
    "    for item in divs:\n",
    "        dict_list = {}\n",
    "        clase_alta = BeautifulSoup(str(item),'html.parser')\n",
    "        nombre_carro = clase_alta.find(estructura_1[0], class_=estructura_1[1]).text\n",
    "        precio_carro = clase_alta.find(estructura_2[0], class_=estructura_2[1]).text\n",
    "        imagenes = clase_alta.find_all(imagen[0], class_=imagen[1])\n",
    "        for img in imagenes:\n",
    "            url_imagen = img.get('src')\n",
    "            if not url_imagen.endswith('.webp'):\n",
    "                url_imagen = img.get('data-src')\n",
    "            else:\n",
    "                url_imagen = img.get('src')\n",
    "        dict_list['Nombre'] = nombre_carro\n",
    "        dict_list['Precio'] = precio_carro\n",
    "        dict_list['Imagen_URL'] = url_imagen\n",
    "        carros.append(dict_list)\n",
    "    return carros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://carros.tucarro.com.co/_Desde_529_NoIndex_True'\n",
    "main_div = ['div','andes-card poly-card poly-card--grid-card andes-card--flat andes-card--padding-0 andes-card--animated']\n",
    "estructura_1 = ['h2','poly-box poly-component__title']\n",
    "estructura_2 = ['span','andes-money-amount__fraction']\n",
    "imagen = ['img','poly-component__picture']\n",
    "carros = extract_cars(url,main_div,estructura_1,estructura_2,imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "carros\n",
    "with open('carros.csv', mode='a', newline='') as file: \n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Nombre_Imagen', 'Precio'])\n",
    "    file.seek(0, os.SEEK_END)  \n",
    "    if file.tell() == 0:\n",
    "        writer.writerow(['Nombre_Imagen', 'Precio']) \n",
    "    for item in carros:\n",
    "        try:\n",
    "            nombre_imagen = item['Nombre'].replace(' ', '_') + '.webp'\n",
    "            ruta_imagen = os.path.join('imagenes_carros', nombre_imagen)\n",
    "            response = requests.get(item['Imagen_URL'])\n",
    "            response.raise_for_status()\n",
    "            with open(ruta_imagen, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            writer.writerow([nombre_imagen, item['Precio']])\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cars_2(url,main_div,estructura_1,estructura_2,img_src):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # clase_sup = soup.find_all(\"lo\", {\"class\":'ui-search-layout ui-search-layout--grid'})\n",
    "    divs = soup.find_all(main_div[0], {\"class\":main_div[1]})\n",
    "    # print(divs)\n",
    "    carros = []\n",
    "    for item in divs:\n",
    "        dict_list = {}\n",
    "        clase_alta = BeautifulSoup(str(item),'html.parser')\n",
    "        nombre_carro = clase_alta.find(estructura_1[0], itemprop=estructura_1[1]).text\n",
    "        precio_carro = clase_alta.find(estructura_2[0], class_=estructura_2[1]).text\n",
    "        imagenes = clase_alta.find_all(img_src[0], itemprop_=img_src[1])\n",
    "        url_imagen = ''\n",
    "        for img in imagenes:\n",
    "            url_imagen = img.get('src')\n",
    "            if not url_imagen.endswith('.webp'):\n",
    "                url_imagen = img.get('data-src')\n",
    "            else:\n",
    "                url_imagen = img.get('src')\n",
    "        dict_list['Nombre'] = nombre_carro\n",
    "        dict_list['Precio'] = precio_carro\n",
    "        dict_list['Imagen_URL'] = url_imagen\n",
    "        carros.append(dict_list)\n",
    "    return carros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.autocosmos.com.co/catalogo/vigente/audi'\n",
    "main_div = ['section','section m-brand']\n",
    "estructura_1 = ['meta','model']\n",
    "estructura_2 = ['span','model-card__price']\n",
    "img_src = ['img','image']\n",
    "carros_brand = extract_cars_2(url,main_div,estructura_1,estructura_2,img_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Nombre': '',\n",
       "  'Precio': '\\n\\n\\n\\nPrecio de lista a partir de:$155.400.000\\n',\n",
       "  'Imagen_URL': ''}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carros_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "carros_brand\n",
    "with open('carros_2.csv', mode='a', newline='') as file: \n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Nombre_Imagen', 'Precio'])\n",
    "    file.seek(0, os.SEEK_END)  \n",
    "    if file.tell() == 0:\n",
    "        writer.writerow(['Nombre_Imagen', 'Precio']) \n",
    "    for item in carros_brand:\n",
    "        try:\n",
    "            nombre_imagen = item['Nombre'].replace(' ', '_') + '.webp'\n",
    "            ruta_imagen = os.path.join('car_brand', nombre_imagen)\n",
    "            response = requests.get(item['Imagen_URL'])\n",
    "            response.raise_for_status()\n",
    "            with open(ruta_imagen, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            writer.writerow([nombre_imagen, item['Precio']])\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
